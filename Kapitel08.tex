\appendix

\newchapter{Funktionalanalysis}
\label{anhang:A}

\section{Sobolev-Räume}
\label{anhang:A.1}

Sei im Weiteren $\emptyset \not= \Omega \subset \R^n$. Wir definieren den Sobolev-Raum allgemein wie folgt (vgl. \cite{BraeFEM} Kaptitel II, \S 2 und \cite{Walker} Kapitel 6).

\begin{defi}\label{def:A.1}
  Seien $1\leq p\leq\infty$ und $m\in\N$. Die Menge
  \[
  W_p^m(\Omega):=\left(
    \{u\in L_p(\Omega)\with\partial^\alpha u\in L_p(\Omega)\,\fa\,\abs a\leq m\}
    , \norm \cdot_{W_p^m}
  \right)
  \]
  heißt \textit{\idx{Sobolev-Raum}} der Ordnung $m$. Dabei ist 
  \[
  \norm u_{W_p^m}:=\norm u_{W_p^m(\Omega)}:=
  \left(
    \sum_{\abs\alpha\leq m}\norm{\partial^\alpha u}_{L_p}^p
  \right)^{\frac 1p},
  \]
  wenn $1\leq p<\infty$. Im Fall $p=\infty$ ist $\norm u_{W_p^m}:=\max_{\abs\alpha\leq m}\norm{\partial^\alpha u}_\infty$. 
  
  Weiterhin bezeichne $L_p(\Omega)$ den \textit{\idx{Lebesgue-Raum}}, d.h. den Raum der messbaren Funktionen, deren $p$-te Potenz Lebesgue-integrierbar über $\Omega$ ist, d.h.
  \[
  	L_p(\Omega) := \left( \{u : \Omega \ra \R \with f \text{ messbar}, \norm{\cdot}_{L_p} < \infty\},\norm{\cdot}_{L_p} \right) \, ,
  \]
  wobei $\norm{u}_{L_p} := \norm{u}_{L_p(\Omega)} =\norm{u}_{W^0_p}$.
\end{defi}

\begin{defi}\label{def:A.2}
Der Raum
\[
	\mcal D(\Omega) := C_c^\infty (\Omega)= \{ \varphi \in C^\infty(\Omega) \with \supp (\varphi) \subset\subset \Omega \}
\]
heißt der \textit{\idx{Raum der Testfunktionen}}, wobei $K\subset\subset \Omega :\Lra  \bar K \subset \Omega$ kompakt.
\end{defi}

\begin{bem}\label{bem:A.3}
 Seien $u\in W_p^m(\Omega)$, $\varphi\in\D(\Omega)$ und $\alpha\in\N^n$ mit $\abs\alpha\leq m$. Dann  bezeichnen wir $v = \partial^\alpha u$ als \textit{\idx{schwache Ableitung}} von $u$, wenn gilt
    \[
      \int_\Omega v\cdot\varphi \, d x=(-1)^{\abs\alpha}\int_\Omega u\cdot\partial^\alpha\varphi \,  d x\, .
    \]
\end{bem}

\begin{bsp}\label{bsp:A.4}
Es sei $\Omega = (-1,1) \subset \R$ und $u (x) = \abs x \in L_2(\Omega)$. Betrachten wir $v (x) = \sign (x)$, so ergibt sich für $\varphi \in \mcal D(\Omega)$
\begin{align*}
	\int_\Omega v \cdot \varphi \, dx & = \int_{-1}^0 -1 \cdot \varphi(x) \, dx + \int_0^1 1\cdot \varphi(x) \, dx  \\
	&= -x\varphi(x)\Big|_{-1}^0 - \int_{-1}^0 -x \varphi'(x) \, dx +  x \varphi(x)\Big|_0^1 -\int_0^1 x \varphi'(x) \, dx \\
	& = - \int_{-1}^1 \abs x \varphi'(x) \, dx = (-1)^1 \int_\Omega u \cdot \varphi' \, dx \, ,
\end{align*}
da $\varphi(-1) = \varphi(1) = 0$. Also ist $v = \partial u$ und somit $u \in W^1_2(\Omega)$. Analog kann man nachrechnen, dass 
\[
	\int_\Omega v \cdot \varphi' \, dx = -2\varphi(0)
\]
ist und somit $u$ nicht zweimal schwach ableitbar ist, d.h. $u \not \in W^2_2(\Omega)$.
\end{bsp}

Wir wollen in der Theorie der Finiten Elemente Methode vor allem Sobolev-Räume über dem Raum $L_2(\Omega)$ betrachten, daher ist folgender Satz essentiell.

\begin{satz}\label{satz:A.5}
Es seien $1\le p \le \infty$ und $m \in \N$. Dann gilt:
\begin{enumerate}[\rm (a)]
\item $W_p^m(\Omega)$ ist ein Banachraum.
\item $H^m(\Omega) := W_2^m(\Omega)$ ist ein Hilbertraum mit Skalarprodukt
\[
	(u,v)_m := (u,v)_{H^m(\Omega)} := \sum_{\abs \alpha \le m} (\partial^\alpha u,\partial^\alpha v)_0\quad \forall \, u,v \in H^m(\Omega) \, ,
\]
wobei
\[
	(u,v)_0 := (u,v)_{L_2(\Omega)} := \int_\Omega uv \, dx \, .
\]
\end{enumerate}
\end{satz}

\begin{bem}\label{bem:A.6}
\begin{enumerate}[(a)]
\item Die Norm auf $H^m(\Omega)$ ergibt sich analog zur Norm des allgemeinen Sobolev-Raumes durch das Skalarprodukt, d.h. $\norm{u}_m: = \norm u_{H^m(\Omega)} := \norm u_{W^m_2}$.
\item Analog dazu definieren wir die Halbnorm $\abs\cdot_m$ auf $H^m$ wie folgt:
\[
		\abs{u}_m: = \abs u_{H^m(\Omega)} :=  \left(
    \sum_{\abs\alpha= m}\norm{\partial^\alpha u}^2_{L_2}
  \right)^{\frac 12}.
\]
\end{enumerate}
\end{bem}

\begin{defi}\label{def:A.7}
Der Raum $H^m_0(\Omega)$ ist die Vervollständigung von $\mcal D(\Omega)$ bzgl. der Norm $\norm\cdot_m$.
\end{defi}

\begin{bem}\label{bem:A.8}
Die Funktionen $u \in H^m_0(\Omega)$ können als die Funktionen $u \in H^m(\Omega)$ mit $u = 0$ auf $\partial \Omega$ aufgefasst werden. Weiter ist $H^m_0(\Omega)$ ein abgeschlossener Unterraum von $H^m(\Omega)$ (vgl. auch \cite{Walker} Bemerkung 6.7).
\end{bem}


\begin{theorem}[\idx{Spursatz}]
  \label{theorem:A.9}
  Es sei $\Omega\subset\R^n$ und $C^2$. Dann gilt für $1<p<\infty$, dass ein $c>0$ existiert mit
  \[ \norm{u\rvert_{\partial\Omega}}_{L_p(\partial\Omega)}\leq c\, \norm u_{W_p^1(\Omega)} \]
  für alle $u\in C^\infty(\bar\Omega)$.

  Die Restriktion $[u\mapsto u\rvert_{\partial\Omega}]$ lässt sich also eindeutig stetig zum Spuroperator $\gamma_0\in\L(W_p^1(\Omega),L_p(\partial\Omega))$ fortsetzen.
\end{theorem}


\section{Optimalitätskriterien}
\label{anhang:A.2}

Zunächst definieren wir einen verallgemeinerten Begriff der Richtungsableitung, der auch auf unendlich dimensionalen Vektorräumen existiert.

\begin{defi}\label{def:Gateaux-Ableitung}
Es seien $V$ ein Vektorraum, $M\subset V$ und $W$ ein normierter Raum, sowie $F: M \ra W$ eine Abbildung, $x_0 \in M$ und $v \in V$. Dann heißt $F$ \textit{\idx{Gâteaux-differenzierbar}} (bzw. in Richtung $v$ an der Stelle $x_0$ differenzierbar), falls es ein $\eps >0$ mit $[x_0-\eps v, x_0 + \eps v] \subset M$ gibt und der Grenzwert
\begin{align}\label{eq:A.1}
	\mscr D_v F (x_0) :=\frac d{d t} F(x_0+tv)\Big|_{t=0} := \lim_{t\ra 0} \frac{F(x_0+tv)-F(x_0)}t
\end{align}
in $W$ existiert. $\mscr D_vF(x_0)$ heißt dann \textit{\idx{Gâteaux-Ableitung}} von $F$ an der Stelle $x_0$ in Richtung $v$.

Falls wir nur $[x_0,x_0 + \eps v] \subset M$ voraussetzen, so können wir in \eqref{eq:A.1} $\lim_{t\ra 0}$ durch $\lim_{t \ra + 0}$ ersetzen. Dann nennen wir \eqref{eq:A.1} die \textit{rechtsseitige Gâteaux-Ableitung}\index{Gâteaux-Ableitung!rechtsseitig} und bezeichnen diese mit $\mscr D^+_v F(x_0)$.
\end{defi}

Für die Variationsrechnung sind folgende zwei Sätze für uns von besonderer Bedeutung.

\begin{satz}\label{satz:A.10}
\textnormal{(Charakterisierungssatz der konvexen Optimierung)} Es seien $M \subset V$ eine konvexe Menge, $V$ ein Vektorraum und $F : M \ra \R$ ein konvexes Funktional. Dann gilt für $x_0, x \in M$:

$x_0$ ist Lösung von $\min\limits_{x \in M} F(x)$ genau dann, wenn für alle $x \in M$ gilt
\[
	\mscr D^+_{x-x_0} F(x_0) \ge 0 \, .
\]
\end{satz}

\begin{proof}
Siehe \cite{GopRieTam}, Kapitel 3.3.3, Satz 3.34.
\end{proof}

\begin{satz}
Es sei $U\subset V$ ein (Unter-)Vektorraum, $V$ ein Vektorraum und $F: U \ra \R$ eine \idx{Gâteaux-differenzierbar}e konvexe Funktion. Dann ist $x_0 \in U$ genau dann Lösung von $\min\limits_{x \in U} F(x)$, wenn für alle $u \in U$ gilt
\[
	\mscr D_u F(x_0) = 0 \, .
\]
\end{satz}

\begin{proof}
Siehe \cite{GopRieTam}, Kapitel 3.3.3, Satz 3.35.
\end{proof}


\section{Konvergenzbegriffe}
\label{anhang:A.3}

\begin{defi}\label{defi:A.12}
Es sei $m\in \N, 1\leq p < \infty, 1 = \frac 1 p + \frac 1 {p'}$.
\begin{enumerate}[(a)]
\item Eine Folge $(u_j)$ in $L_p$ konvergiert schwach gegen $u \in L_p(\Omega)$
\begin{align*}
	&: \Longleftrightarrow u_j \rightharpoonup u \text{ in } L_p(\Omega) \\
	& : \Longleftrightarrow \, \fa \, v \in L_{p'}(\Omega) : \int_\Omega u_j v \d x \longrightarrow \int_\Omega uv \d x \text{ in } \K \, .
\end{align*}
\item Eine Folge $(u_j) \in W^m_p(\Omega)$ konvergiert schwach gegen $u \in W_p^m (\Omega)$
\begin{align*}
	& : \Longleftrightarrow u_j \rightharpoonup u \text{ in } W_p^m(\Omega) \\
	& : \Longleftrightarrow \partial^\alpha u_j \rightharpoonup \partial^\alpha u \text{ in } L_p(\Omega) \, \forall \, \abs\alpha \leq m \, .
\end{align*}
\end{enumerate}
\end{defi}


\begin{bem}
\label{bem:A.13}
Sei $1\leq p < \infty, m \in \N$, dann ist:
\begin{enumerate}[(a)]
\item Ist $u_j \ra u$ in $W^m_p(\Omega)$, dann folgt $u_j \rightharpoonup u$ in $W^m_p(\Omega)$, d.h. "`starke Konvergenz ist stärker als schwache Konvergenz"'.
\begin{proof}
$\fa \, v \in L_{p'}(\Omega), \abs \alpha \leq m$ gilt
\[
	\Abs{\int_\Omega (\partial^\alpha u_j - \partial^\alpha u) v \d x} \stackrel[\scriptsize\text{Hölder}]{}\leq \norm v_{L_{p'}(\Omega)} \norm{\partial^\alpha u_j -\partial^\alpha u }_{L_p(\Omega)} \longrightarrow 0 \, .\qedhere
\]
\end{proof}
\item Sei $1 < p < \infty, (u_j)\subset W^m_p(\Omega)$ beschränkt (bzgl. $\norm{\, \cdot\, }_{W^m_p}$), dann folgt, dass eine Teilfolge $(u_{j'})$ und ein $u \in W^m_p(\Omega)$ existiert, so dass $u_{j'} \rightharpoonup u$ in $W^m_p(\Omega)$, d.h. "`beschränkte Folgen sind relativ schwach kompakt"'.
\begin{proof}
Vgl. \cite{Rudin}.
\end{proof}
\item Es sei $M\subset W^m_p(\Omega)$ konvex und abgeschlossen (bzgl. $\norm{\, \cdot\, }_{W^m_p}$), sowie $(u_j) \subset M$ mit $u_j \rightharpoonup u $ in $W^m_p(\Omega)$, dann ist $u \in M$, d.h. "`abgeschlossene konvexe Mengen sind schwach abgeschlossen"' (Theorem von Mazun; ohne Beweis, vgl. \cite{Rudin}).
\item Es sei $u_j \rightharpoonup u $ in $W^p_m (\Omega)$, dann folgt $(u_j)$ ist beschränkt in $W^m_p(\Omega)$ (bzgl. $\norm{\, \cdot\, }_{W^m_p}$), d.h. "`schwach konvergente Folgen sind beschränkt"'.
\begin{proof}
Theorem von Mackey, vgl. \cite{Rudin}.
\end{proof}
\item $u_ j \rightharpoonup u $ in $W^m_p(\Omega), u_j \rightharpoonup v$ in $W^m_p(\Omega)$, dann gilt $u=v$, d.h. "`Grenzwerte von schwach konvergenten Folgen sind eindeutig"'.
\begin{proof}
Aus dem Hauptsatz der Variationsrechnung folgt die Behauptung.
\end{proof}
\item Sei $u_j \rightharpoonup u $ in $W^m_p(\Omega)$, dann folgt $\norm u_{W^m_p(\Omega)} \leq \lim \inf \norm{u_j}_{W^m_p(\Omega)}$.
\end{enumerate}
\end{bem}

\begin{theorem}\label{theorem:A.14}
In einem reflexiven Raum $V$\index{reflexiver Raum}, d.h. der Bidualraum $V''$ ist isomorph zu $V$, besitzt jede beschränkte Folge $(v_n)_{n\in \N}$ eine schwach konvergente Teilfolge $(v_{n_j})$.
\end{theorem}

\begin{proof}
Der Beweis befindet sich in \cite{Werner} Kapitel III, Theorem 3.7.
\end{proof}

\begin{bem}\label{bem:A.15}
Jeder Hilbertraum $H$ ist reflexiv.
\end{bem}

\begin{proof}
Dies folgt aus dem Darstellungssatz von Riesz (Satz \ref{satz:2.15}).
\end{proof}










\newchapter{Optimierung}
\label{anhang:B}

\section{Quadratische Programmierung}
\label{anhang:B.1}

Um im folgenden die Idee des Algorithmus zu verstehen, führen wir zunächst grundlegende Begriffe ein. Ein quadratisches Problem mit Gleichungs- und Ungleichungsnebenbedingungen ist von der Form
\begin{align}\label{eq:QP}
\begin{aligned}
	\min_{\bs x} & \quad q(\bs x) = \frac 1 2 \bs x^T G\bs x + \bs x^T \bs c \\
	\text{s.t.} & \quad \bs a_i^T \bs x = b_i \, , \quad i \in \mcal E, \\
	& \quad \bs a_i^T \bs x\ge b_i \, , \quad i \in \mcal I,
\end{aligned}
\end{align}
wobei $\mcal E$ und $ \mcal I$ die Indexmengen der Gleichungs- und Ungleichungsnebenbedingungen darstellen und $\bs c,\bs x,\bs a_i \in \R^n, b_i \in \R, i \in \mcal E \cup \mcal I$, sowie $G$ eine symmetrische $(n\times n)$-Matrix ist, welche die Hesse-Matrix des Problems darstellt. Damit ist die Hesse-Matrix konstant und daher das Problem konvex, wenn $G$ positiv semidefinit ist. (Ist $G$ positiv definit, so nennen wir das Problem strikt konvex. Wenn $G$ indefinit ist, ist \eqref{eq:QP} "`nicht konvex"'.)

Da sonst das quadratische Problem (und damit der Active-Set Algorithmus) zu kompliziert wird, betrachten wir hier nur den konvexen Fall. Für diesen Fall können wir leicht zeigen, dass eine Lösung $\bs x^*$, die die Bedingungen 1. Ordnung erfüllt, auch globale Lösung des Problems ist (s. Theorem \ref{A.1}). Anschaulich kann es im indefiniten Fall mehrere optimale Punkte geben, die voneinander getrennt liegen, d.h. die Menge der optimalen Punkte ist nicht zusammenhängend, wodurch das Auffinden des globalen Minimums erschwert wird.

Die notwendigen Bedingungen 1. Ordnung sind die KKT-Bedingungen und können hier angewendet werden, da die Restriktionen und die Zielfunktion stetig differenzierbar sind. Die Lagrangefunktion $\mcal L$ für das quadratische Problem ist
\begin{align}
	\mcal L(\bs x,\bs\lambda) = \frac 1 2 \bs x^T G \bs x + \bs x^T \bs c- \sum_{i \in \mcal I \cup \mcal E} \lambda_i (\bs a_i^T \bs x-b_i) \, .
\end{align}
Damit ergeben sich –  vgl. \cite{NocWri}, Theorem 12.1 – mit der Menge der aktiven Nebenbedingungen $\mcal A(\bs x^*) = \{i\in \mcal E \cup \mcal I : \bs a_i^T \bs x^* = b_i\}$ die KKT-Bedingungen
\begin{align}\label{eq:KKT}
\begin{aligned}
	\nabla_{\bs x} \mcal L(\bs x^*,\bs \lambda^*) & = G\bs x^*+\bs c-\sum_{i \in \mcal A(\bs x^*)} \lambda^*_i \bs a_i  = 0 \, , \\
	\bs a_i^T \bs x^* &  = b_i \, , \quad \forall \, i \in \mcal A(\bs x^*) , \\
	\bs a_i^T \bs x^* &  \ge b_i \, , \quad \forall \, i \in \mcal I \setminus \mcal A(\bs x^*) ,\\
	\lambda_i^* & \ge 0 \, , \quad \, \forall i \in \mcal I \cap \mcal A(\bs x^*) .
\end{aligned}
\end{align}
Hierbei ist $\bs x^*$ Lösung von \eqref{eq:QP} und erfüllt die LICQ-Bedingung; $\bs\lambda^*$ ist dazugehöriger optimaler Lagrange-Multiplikator. In \eqref{eq:KKT} wird die Komplementaritätsbedingung $\lambda^*_i c_i(\bs x^*) = 0$ impliziert durch $\lambda_i^* = 0 \, \forall \, i \not\in \mcal A(\bs x^*)$.

\begin{theorem}\label{theorem:B.1}
Wenn $\bs x^*$ die Bedingungen \textnormal{\eqref{eq:KKT}} erfüllt mit $\lambda_i^*,i \in \mcal A(\bs x^*)$ und $G$ ist positiv semidefinit, dann ist $\bs x^*$ eine globale Lösung von \textnormal{\eqref{eq:QP}}.
\end{theorem}

\begin{proof}
Wenn $\bs x$ ein beliebiger weiterer zulässiger Punkt für (1.1) ist, gelten die Restriktionen $\bs a_i^T\bs x = b_i,  i \in \mcal E$,  sowie $\bs a_i^T \bs x \ge b_i, i \in \mcal I \cap \mcal A(\bs x^*)$ für $\bs x$ und damit gilt zusammen mit der ersten Bedingung von \eqref{eq:KKT}, dass
\[
	(\bs x-\bs x^*)^T (G\bs x^*+\bs c) = \sum_{i \in \mcal E} \underbrace{\lambda^*_i \bs a_i^T (\bs x-\bs x^*)}_{\ge 0} + \sum_{i \in \mcal A(x^*)\cap \mcal I} \underbrace{\lambda^*_i \bs a_i^T (\bs x-\bs x^*)}_{\ge 0} \ge 0 \, .
\]
Dann drücken wir $q(\bs x)$ durch $q(\bs x^*)$ aus und wenden die obere Ungleichung sowie die positive Semidefinitheit für $G$ an, um zu zeigen, dass $q(\bs x) \ge q(\bs x^*)$ ist. Damit ist $\bs x^*$ globale Lösung des quadratischen Problems.
\end{proof}

Daher ist im positiv semidefiniten Fall gesichert, dass ein optimaler Punkt auch gleichzeitig globale Lösung ist.


\section{Active Set-Methode für konvexe QPs}
\label{anhang:B.2}

Wenn wir eine Lösung $\bs x^*$ für das Problem \eqref{eq:QP} kennen, so ist auch die Menge der aktiven Nebenbedingungen $\mcal A(x^*)$ bekannt und wir können \eqref{eq:QP} vereinfachen zum Optimierungsproblem
\begin{align}\label{eq:active}
	\min_{\bs x} & \quad q(\bs x) = \frac 1 2 \bs x^T G \bs x+\bs x^T \bs c \, , \quad	\text{s.t.} \quad \bs a_i^T\bs x = b_i \, , \quad i \in \mcal A(\bs x^*)\, .
\end{align}
Dieses könnten wir dann beispielsweise mit direkten Verfahren wie der Schur-Komplement-Methode oder der Nullraum-Methode lösen. Natürlich ist die optimale Lösung zu Beginn noch nicht bekannt und damit auch nicht die aktiven Restriktionen. Jedoch können wir diese Idee für die Active-Set-Methode verwenden.

Das Hauptziel der Active-Set-Methode ist, die Menge der aktiven Restriktionen bzgl. der optimalen Lösung zu finden, wobei wir hier die primale Variante betrachten wollen, in der die Approximierte $\bs x_k$ zulässig bzgl. des primalen Problems ist. 

Die Grundidee ist, ein quadratisches Teilproblem zu lösen, bei dem wir bestimmte Nebenbedingungen aus Problem \eqref{eq:QP} bzgl. $\mcal I$ als aktiv annehmen. Die dadurch beschriebene Indexmenge der aktiven Restriktionen für $\bs x_k$ im $k$-ten Schritt heißt \textit{working set} und kann wie folgt beschrieben werden
\[
	\mcal W_k = \{ i \, | \, \bs a_i^T \bs x_k = b_i,  i \in \mcal E \cup \mcal J, \mcal J \subset \mcal I\} \, .
\]
Hierbei muss vorausgesetzt werden, dass die Nebenbedingungen in $\mcal W_k$ die LICQ-Bedingung erfüllen, selbst wenn diese bezogen auf alle Nebenbedingungen an der Stelle $x_k$ nicht erfüllt wird.

Wir betrachten nun den $k$-ten Schritt mit der Approximierten $\bs x_k$ und dem working set $\mcal W_k$. Wir berechnen die neue Iterierte $\bs x_{k+1}$, indem wir eine Richtung $\bs p$ finden, in der wir unter den Nebenbedingungen $\mcal W_k$ die Funktion $q$ minimieren. Hierfür betrachten wir $\bs x_{k+1} = \bs x_k + \bs p$ und setzen $\bs x_{k+1}$ in $q$ ein:
\begin{align*}
	 q(\bs x_{k+1}) & = q(\bs x_k+\bs p) = \frac 1 2 (\bs x_k + \bs p)^T G (\bs x_k + \bs p) + (\bs x_k + \bs p)^T \bs c \\
	& = \frac 1 2 \bs x^T_k G \bs x_k + \underbrace{\bs x_k^T G \bs p}_{\text{da $G$ symm.}} + \frac 1 2 \bs p^T G\bs p +\bs x_k^T \bs c +\bs p^T \bs c \\
	& = \frac 1 2\bs p^T G \bs p +\bs  g_k^T \bs p + \rho_k \, ,
\end{align*}
wobei $\bs g_k = G\bs x_k+\bs c$ und $\rho_k = \frac 1 2 \bs x_k^T G \bs x_k + \bs x_k^T \bs c$. Da wir den Parameter $\bs p$ so wählen wollen, so dass $q(\bs x_{k+1})$ minimal wird, ist der Term $\rho_k$ bzgl. des Problems konstant und  kann somit für die Lösung jenes weggelassen werden. Da weiterhin auch $\bs x_{k+1}$ die aktiven Nebenbedingungen $\mcal W_k$ erfüllen soll, gilt
\[
	\bs a_i^T \bs p =\bs a_i^T (\bs x_{k+1} - \bs x_k) = \underbrace{\bs a_i^T\bs x_{k+1}}_{=b_i} - \underbrace{\bs a_i^T \bs x_k}_{=b_i} = 0 \quad \forall \, i \in \mcal W_k \, .
\]
Zusammengefasst müssen wir also im $k$-ten Schritt das Teilproblem
\begin{align}\label{eq:subprob}
\begin{aligned}
	\min_{\bs p} & \quad \frac 1 2\bs p^T G \bs p + \bs g_k^T \bs p \, , \\
	\text{s.t.} & \quad \bs a_i^T\bs p = 0 \, , \quad \forall i \in \mcal W_k 
\end{aligned}
\end{align}
lösen. Die Lösung im $k$-ten Schritt von \eqref{eq:subprob} bezeichnen wir mit $\bs p_k$. Umgekehrt gilt damit, analog zur obigen Rechnung, natürlich auch, dass für alle $i \in \mcal W_k$ die Restriktion aktiv bleibt für $\bs x_k + \alpha \bs p_k$ mit beliebigem $\alpha$. Da $G$ positiv definit ist, kann \eqref{eq:subprob} nun – wie schon bei \eqref{eq:active} erwähnt – mit Schur-Komplement-Methode oder Nullraum-Methode gelöst werden.

Wie wir schon wissen, ist die neue Iterierte $\bs x_{k+1} = \bs x_k + \bs p_k$ bzgl. $\mcal W_k$ immer noch zulässig. Nun müssen wir jedoch feststellen, ob diese Iterierte auch alle übrigen Restriktionen mit $i\not\in \mcal W_k$ erfüllt. Ist dies der Fall, so setzen wir $\bs x_{k+1} = \bs x_k +\bs p_k$, ansonsten suchen wir das größtmögliche $\alpha_k \in [0,1]$, so dass
\[
	\bs x_{k+1} =\bs x_k + \alpha_k \bs p_k
\] 
zulässig bleibt. Hierfür betrachten wir zwei Fälle.

\underline{Fall 1:} Gilt für ein $i \not \in \mcal W_k$, dass $\bs a_i^T \bs p_k \ge 0$ ist, so folgt
\[
	\bs a_i^T (\bs x_k + \alpha_k \bs p_k) =\bs a_i^T \bs x_k + \underbrace{\alpha_k \bs a_i^T\bs p_k}_{\ge 0} \ge \bs a_i^T \bs x_k \ge b_i \, ,
\]
da $\alpha_k \ge 0$, d.h. für diese Nebenbedingungen müssen wir für die Wahl von $\alpha_k$ nichts beachten.

\underline{Fall 2:} Existiert ein $i \not \in \mcal W_k$, für das $\bs a_i^T\bs p_k < 0$ ist, so gilt
\begin{align}\label{eq:alpha}
\notag	& \bs a_i^T (\bs x_k + \alpha_k \bs p_k) \ge b_i \\
\notag	\Llra \quad &\bs a_i^T \bs x_k + \alpha_k \bs a_i^T\bs p_k \ge b_i \\
\notag	\Llra \quad & \alpha_k \underbrace{\bs a_i^T\bs p_k}_{< 0} \ge b_i - \bs a_i^T \bs x_k \\
	\Llra \quad &  \alpha_k \le \frac{b_i - \bs a_i^T\bs x_k }{\bs a_i^T \bs p_k} \, .
\end{align}

Damit folgt mit \eqref{eq:alpha} und den vorherigen Überlegungen, dass zusammengefasst
\begin{align}\label{eq:alpha_k}
	\alpha_k = \min\left\{ 1,\min_{i \not\in \mcal W_k, \bs a_i^T\bs p_k < 0}  \frac{b_i -\bs a_i^T\bs x_k }{\bs a_i^T \bs p_k}  \right\}
\end{align}
gilt. Eine Restriktion $i \not \in \mcal W_k$, für die das Minimum für $\alpha_k$ angenommen wird, nennen wir \textit{blocking constraint}; diese muss nicht eindeutig sein, da wir beispielsweise anschaulich auch von einer Ecke geblockt werden können. Ist $\alpha_k = 1$, so werden alle Restriktion außerhalb vom {working set} mit dem Schritt $\bs x_{k+1} =\bs x_k + \bs p_k$ erfüllt, d.h. es gibt keine {blocking constraint}. Gibt es eine Nebenbedingung $j \not\in \mcal W_k$, die aktiv ist, obwohl sie nicht zum working set gehört, so gilt
\begin{align*}
	\alpha_k & = \min\left\{ 1,\min_{i \not\in \mcal W_k, \bs a_i^T\bs p_k < 0}  \frac{b_i -\bs a_i^T\bs x_k }{\bs a_i^T\bs p_k}  \right\}  \\
	& = \min\left\{ 1, \frac{b_j - {\bs a_j^T \bs x_k}}{\bs a_j^T\bs p_k}  \right\}  \\
	&  = \min \left\{1,\frac{b_j-b_j}{\bs a_j^T\bs p_k}\right\} = 0 \, .
\end{align*}
Es sei $j \not \in \mcal W_k$ nun ein Index einer {blocking constraint}. Dann ist
\[
	\bs x_{k+1} =\bs x_k + \alpha_k \bs p_k = \bs x_k + \frac{b_j - {\bs a_j^T \bs x_k}}{\bs a_j^T\bs p_k}\bs p_k \, .
\]
Setzen wir $\bs x_{k+1}$ in die $j$-te Restriktion ein, so erhalten wir
\begin{align*}
	\bs a_j^T\bs x_{k+1} & = \bs a_j^T \( \bs x_k +  \frac{b_j - \bs a_j^T\bs x_k}{\bs a_j^T\bs p_k}\bs p_k  \) = \bs a_j^T\bs x_k + \frac{b_j - {\bs a_j^T\bs x_k}}{\cancel{\bs a_j^T\bs p_k}} \cdot \cancel{\bs a_j^T\bs p_k} \\
	& =\bs a_j^T\bs x_k + b_j -\bs a_j^T\bs x_k = b_j \, ,
\end{align*}
d.h. die {blocking constraint} ist für die neue Iterierte $\bs x_{k+1}$ nach Konstruktion aktiv. Daher setzen wir als neues {working set} $\mcal W_{k+1} = \mcal W_k \cup \{ j\}$.

Das oben beschriebene Vorgehen wiederholen wir so lange, bis wir das {working set} $\hat {\mcal W}$ mit dem Minimum des quadratischen Problems $\hat{\bs x}$ gefunden haben. Dies ist leicht zu erkennen, da wir \eqref{eq:QP} auf $\mcal W_k$ nicht weiter minimieren können, sobald es keinen Schritt $p$ gibt, in dessen Richtung wir $q$ verringern können, d.h. wenn $\bs p = \bs 0$ die Lösung für das Teilproblem \eqref{eq:subprob} ist.  Dann ist der optimale Punkt $\hat{\bs x}$ bzgl. des {working sets} $\hat{\mcal W}\subset \mcal A(\hat{\bs x})$ gefunden.

Wir müssen jetzt überprüfen, ob $\hat{\bs x}$ die KKT-Bedingungen erfüllt. Wir wissen, dass für $\bs p= \bs 0$ die KKT-Bedingungen für \eqref{eq:subprob}
\begin{align*}
\begin{pmatrix}
	G & A^T \\
	A & 0
\end{pmatrix} \cdot
\begin{pmatrix} 
-\bs p \\
\hat{\bs\lambda}
 \end{pmatrix} =
 \begin{pmatrix}
 	\hat{\bs g} \\
	\hat{\bs h}
 \end{pmatrix}
\end{align*}
mit $\hat{\bs g} = \bs c + G\hat{\bs x}, \bs h = A\hat{\bs x}+\bs b$ und $\bs p=\bs 0$ erfüllt. Daraus folgt
\begin{align*}
	A^T \hat{\bs \lambda} = \hat{\bs g}  \quad &\Llra \quad \sum_{i \in \hat{\mcal W}}\bs a_i \hat\lambda_i = G\hat{\bs x} +\bs c \, , \\
	\bs 0 = \hat{\bs h} \quad  & \Llra \quad A\hat{\bs x} =\bs b\, , 
\end{align*}
wobei $A$ die Gradienten $\bs a_i^T$ der aktiven Restriktionen $\hat{\mcal W}$ zeilenweise  enthält. Damit werden die ersten beiden KKT-Bedingungen aus \eqref{eq:KKT} erfüllt. Da die Schrittlänge $\alpha_k$ mit \eqref{eq:alpha} so gewählt ist, dass die übrigen Restriktionen erfüllt bleiben, gilt auch die dritte Bedingung aus \eqref{eq:KKT}. Es bleibt zu überprüfen, ob die Lagrange-Multiplikatoren $\hat\lambda_i \ge 0$ sind.

Gilt $\hat\lambda_i \ge 0$ für alle $i \in \hat{\mcal W} \cap \mcal I$, so sind alle KKT-Bedingungen erfüllt und damit $\bs x^* = \hat{\bs x}$. Existiert allerdings ein $j \in \hat{\mcal W} \cap \mcal I$, so dass $\hat \lambda_j < 0$ ist, so können wir den Wert von $q$ noch weiter verringern, indem wir die $j$-te Restriktion wegfallen lassen (vlg. \cite{NocWri}, Kapitel 12.3). Dies zeigt das folgende Theorem.

\begin{theorem}
Der Punkt $\hat{\bs x}$ erfülle die notwendigen Bedingungen 1. Ordnung für das Teilproblem \textnormal{\eqref{eq:subprob}} auf $\hat{\mcal W}$. Weiter seien die Gradienten $\bs a_i, i \in \hat{\mcal W}$, linear unabhängig $($LICQ$)$ und es gebe einen Index $j \in \mcal W$ mit $\hat \lambda_j<0$. Es sei $\bs p$ die Lösung vom Teilproblem \textnormal{\eqref{eq:subprob}} ohne die Restriktion $j$, d.h.
\begin{align*}
	\min_{\bs p} & \quad \frac 1 2\bs p^T G\bs p + (G\hat{ \bs x} +\bs c)^T\bs p \, , \\
	\textnormal{s.t.} & \quad\bs a_i^T\bs p = 0 \, , \quad  \forall \, i \in \hat{\mcal W} \setminus \{j\} \, .
\end{align*}
Dann ist $p$ eine zulässige Richtung für die Nebenbedingung $j$, d.h. $\bs a_j^T \bs p \ge 0$. Weiterhin gilt sogar $\bs a_j^T\bs p > 0$ und $p$ ist eine Abstiegsrichtung für $q$, wenn $\bs p$ die hinreichenden Bedingungen 2. Ordnung erfüllt.
\end{theorem}

Da wir zeigen können, dass der erzielte Abstieg für $q$ durch das Weglassen einer Nebenbedingung mit negativem Lagrange-Multiplikator $\lambda_i$ proportional zu $\abs{\lambda_i}$ ist, eliminieren wir gerade die Restriktion mit kleinstem Langrange-Multiplikator. Es kann allerdings sein, dass der folgende zu berechnende Schritt $\bs p$ aufgrund einer {blocking constraint} kurz ist, wodurch nicht garantiert ist, dass $q$ den größtmöglichen Abstieg erfährt.

%Wie oben beschrieben fordern wir, dass die Gradienten im {working set} $\mcal W_k$ linear unabhängig sind (LICQ-Bedingung). Betrachten wir nun unsere Strategie in der Active-Set-Methode, in das {working set} Restriktionen hinzuzufügen oder welche aus diesem zu eliminieren, sieht man leicht, dass die Elimination von Nebenbedingungen die lineare Abhängigkeit der Gradienten im working set nicht hervorrufen kann. Man kann zudem zeigen, dass eine {blocking constraint} immer linear unabhängig ist zu den schon bestehenden aktiven Nebenbedingungen. Damit kann auch das Hinzufügen die lineare Unabhängigkeit nicht beeinflussen.
%
%Das Eliminieren und Hinzufügen von Nebenbedingungen führt dazu, dass der in Kapitel 3 aufgerührte Algorithmus eine natürliche untere Schranke erhält. Wenn wir beispielsweise eine Lösung $x^*$ eines Problems haben, in der $m$ der Ungleichungs-Restriktionen aktiv sind, in unserer Startnäherung $x_0$ allerdings keine Ungleichungs-Restriktion, so benötigen wir mindestens $m$ Schritte, um von $x_0$ zu $x^*$ zu gelangen, da wir in jedem Schritt genau eine Nebenbedingung hinzufügen oder eliminieren.


\section{Algorithmus}
\label{anhang:B.3}

\begin{algorithm}[H]
\caption{Active-Set-Methode für konvexe quadratische Probleme}
Gegeben sei ein zulässiger Startpunkt $\bs x_0$ für \eqref{eq:QP} und definiere $\mcal W_0$ z.B. mit allen aktiven Restriktionen bzgl. $\bs x_0$.
\begin{algorithmic}
\For{k = 0,1,2,\ldots}
\State Löse \eqref{eq:subprob} zur Berechnung von $\bs p_k$;
\If {$\bs p_k = \bs 0$}
\State Berechne die Lagrange-Multiplikatoren mittels (2.5a)
\State \quad und setze $\hat{\mcal W} = \mcal W_k$;
\If{$\hat\lambda_i \ge 0 \, \forall \, i \in \hat{\mcal W} \cap \mcal I$}
\State \textbf{stop} mit der Lösung $\bs x^* = \hat{\bs x}$;
\Else
\State $j \la \arg\min_{j\in \mcal W_k \cap \mcal I} \hat\lambda_j;$
\State $\bs x_{k+1} \la \bs x_k, \mcal W_{k+1} \la W_k \setminus \{j\}$;
\EndIf
\Else \quad ($\bs p_k \not= \bs 0$)
\State Berechne $\alpha_k$ mit \eqref{eq:alpha_k};
\State $\bs x_{k+1} \la  \bs x_k + \alpha_k\bs p_k$;
\If {$\alpha_k < 1$ ({blocking constraint} existiert)}
\State Bestimme  blocking constraint $j$ und setze $\mcal W_{k+1} \la \mcal W_k \cup \{j\}$
\Else
\State $\mcal W_{k+1} \la \mcal W_k$
\EndIf
\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}







\newchapter{Tensorrechnung}
\label{anhang:C}


\section{Tensoralgebra}
\label{kap:C.1}


\begin{defi}\label{def:C.1}
Es sei $V$ ein endlicher Vektorraum und $\K$ ein beliebiger Körper. Ein $p$-\textit{\idx{Tensor}} (oder auch $p$-\textit{stufiger Tensor}) $\varphi: V\times \dots \times V \ra \K$ ist eine multilineare Abbildung, d.h. linear in jeder Komponente. Die Menge aller $p$-Tensoren über $V$ wird mit $T^p(V)$ bezeichnet.
\end{defi}

\begin{bsp}\label{bsp:C.2}
Der \idx{Dualraum} $V^*$ eines Vektorraums $V$ ist der Raum der Linearformen, also der Raum der $1$-Tensoren. Also können wir schreiben $V^* = T^1(V)$.
\end{bsp}

\begin{bem}\label{bem:C.3}
Da $V$ endlich ist, können wir $T^p(V)$ durch eine endliche Anzahl von Basisvektoren $\varphi_k \in T^p(V)$ aufspannen. Solche Basisvektoren lassen sich durch die Basis des Dualraumes $V^*$ und der folgenden Definition bilden.
\end{bem}

\begin{defi}[\idx{Tensorprodukt}]\label{def:C.4}
Ist $\varphi \in T^p(V)$ und $\psi \in T^q(V)$, so definieren wir das \textit{\idx{Tensorprodukt}} (oder auch \textit{dyadische Produkt}\index{dyadisches Produkt}) $\varphi \otimes \psi \in T^{p+q}(V)$ durch
\[
	(\varphi \otimes \psi)(v_1,\dots,v_p,v_{p+1},\dots,v_{p+q}) = \varphi (v_1,\dots,v_p)\cdot \psi (v_{p+1},\dots,v_{p+q}) \, .
\]
\end{defi}

\begin{bem*}
Wir sollten beachten, dass $\varphi \otimes \psi$ nicht zwangsläufig kommutativ ist.
\end{bem*}

\begin{bem}\label{bem:C.5}
Da $T^1(V)$ der Raum der Linear- und $T^2(V)$ der Raum der Bilinearformen ist, können wir die Elemente als Vektoren bzw. Matrizen identifizieren. Hierbei ist allerdings zu beachten, dass diese nur die Koordinaten bzgl. der jeweils betrachteten Basen angeben.

Wir notieren einstufige Tensoren, d.h. Elemente aus $T^1(V)$, in fetten Kleinbuchstaben, also $\bs a, \bs b, \bs c$ usw., und schreiben diese bzgl. der Standardbasis
\[
	\bs a = a_i \bs e_i \coloneqq \sum_{i=1}^n a_i \bs e_i \, .
\]

Hierbei ist die \textit{\idx{Einstein'sche Summenkonvention}} benutzt worden, in der über doppelt vorkommende Indizes summiert wird.

Analog beschreiben wir zweistufige Tensoren, also Elemente aus $T^2(V)$, mit fetten Großbuchstaben, d.h. $\bs A, \bs B, \bs C$ etc., und schreiben diese bzgl. der Standardbasis als \idx{Tensorprodukt} von zwei einstufigen Tensoren:
\[
	\bs A = A_{ij} \bs e_i \otimes \bs e_j \coloneqq \sum_{i,j=1}^n A_{ij} \bs e_i \otimes \bs e_j \, .
\]
\end{bem}

\begin{bem*}
Die Tensordarstellung aus Bemerkung \ref{bem:C.5} kann natürlich auch bzgl. allgemeiner Basen geschehen.
\end{bem*}

\begin{defi}[\idx{Kroneckerdelta}, \idx{Einheitstensor}]\label{def:C.6}
Das \textit{Kroneckerdelta} ist definiert durch
\[
	\delta_{ij} \coloneqq \begin{cases}
						1, & i = j \\
						0, & \text{sonst}
					\end{cases} \, .
\]
Damit können wir den zweistufigen \textit{Einheitstensor} definieren durch
\[
	\bs 1\coloneqq \delta_{ij} \bs e_i \otimes \bs e_j \, .
\]
\end{defi}

\begin{bem}\label{bem:C.7}
Wir können leicht nachrechnen, dass das Kroneckerdelta folgende Eigenschaften hat:
\begin{align*}
	\delta_{ij} \delta_{jk} = \delta_{ik} \, , \quad \delta_{ij}\delta_{jk}\delta_{kl} = \delta_{il} \, .
\end{align*}
Mit diesen Eigenschaften können wir beispielsweise 4- oder 6-stufige Einheitstensoren\idx{Einheitstensor} definieren.
\end{bem}

\begin{defi}[Skalarprodukte]\label{def:C.8}
Das \textit{einfach verjüngende \idx{Skalarprodukt}}\index{Skalarprodukt!einfach verjüngend} ist für zwei Vektoren (1-Tensoren) $\bs a, \bs b$ definiert als
\[
	\bs a \cdot \bs b \coloneqq (a_i \bs e_i)\cdot (b_j \bs e_j) = a_i b_j \, \underbrace{\bs e_i \cdot \bs e_j}_{=\delta_{ij}} = a_i b_i \, .
\]
Das \textit{doppelt verjüngende \idx{Skalarprodukt}}\index{Skalarprodukt!doppelt verjüngend} ist für zwei Matrizen (2-Tensoren) $\bs T,\bs S$ definiert als
\begin{align*}
	\bs T : \bs S & = (T_{ij} \bs e_i \otimes \bs e_j) : (S_{kl} \bs e_k \otimes \bs e_l)\coloneqq T_{ij} S_{kl} \,  \delta_{ik} \cdot \delta_{jl} 
	 = T_{ij}S_{ij} \, .
\end{align*}
\end{defi}

\begin{bem}\label{bem:C.9}
Analog können wir die Skalarprodukte aus Definition \ref{def:C.8} auch auf höher stufige Tensoren übertragen. Die Skalarprodukte heißen einfach und doppelt verjüngend, da sie im Endergebnis die Stufe der Tensoren um eins bzw. zwei verringern.
\end{bem}



\section{Tensoranalysis}
\label{kap:C.2}

In dieser Arbeit werden skalar-, vektor- oder auch tensorwertige Funktionen in einem mehrdimensionalen Raum verwendet. Hierfür wollen wir \idx{Gradient} und \idx{Divergenz} einführen.

\begin{defi}[Gradient,Divergenz]\label{def:C.10}
Der \textit{Gradient} einer  skalar-, vektor- oder  tensorwertige Funktionen ist definiert als
\[
	\grad(\ldots) \coloneqq \frac{\partial(\ldots)}{\partial\bs x} \coloneqq \frac{\partial(\ldots)}{\partial x_i}\otimes \bs e_i \coloneqq (\ldots)_{,i} \otimes \bs e_i \, . 
\]
Für den Gradienten schreiben wir auch häufig den Nabla-Operator $\nabla$.

Die \textit{Divergenz} einer skalar-, vektor- oder  tensorwertige Funktionen ist definiert durch
\[
	\div (\ldots) \coloneqq \nabla \cdot (\ldots) = \frac{\partial(\ldots)}{\partial x_i}\cdot \bs e_i = (\ldots)_{,i} \cdot \bs e_i \, .
\]
\end{defi}

\begin{bem*}
Der Gradient vergrößert also die Stufe eines Tensors, während die Divergenz diese verringert.
\end{bem*}

Für den Gradienten und die Divergenz gelten einige Produktregeln bzgl. tensorwertigen Funktionen (von 0. bis 2. Stufe). Folgende werden wir davon benötigen.

\begin{satz}[\idx{Produktregel}n]\label{satz:C.11}
Es seien $\phi(\bs x)$ eine skalarwertiges, $\bs a(\bs x)$ eine vekorwertiges und $\bs T(\bs x)$ ein tensorwertiges $($2. Stufe$)$ Tensorfeld. Dann gelten für die Divergenz folgende Produktregeln.
\begin{align}\label{eq:C.1}
	\div (\phi \cdot \bs a ) &= \grad \phi \cdot \bs a + \phi \cdot \div \bs a \\
	\label{eq:C.2}
	\div (\bs a \cdot \bs T) &= \grad \bs a : \bs T + \bs a \cdot \div \bs T 
\end{align}
\end{satz}

\begin{proof}
Einfaches Nachrechnen.
\end{proof}


Weiter gelten in der Tensoranalysis verschiedene Integralsätze von Gauß, Stokes und Green, von denen wir folgende aufführen wollen, wobei wir uns wieder auf $\Omega \subset \R^2, \partial\Omega = \Gamma$ beschränken.

\begin{satz}[Integralsatz von Gauß]\label{satz:C.12}
Es seien die Tensorfelder $\bs a(\bs x), \bs T(\bs x)$ wie in Satz \ref{satz:C.11} gegeben. Dann gelten die Sätze von Gauß\index{Integralsatz!Gauß}
\begin{subequations}\label{eq:C.3}
\begin{align}\label{eq:C.3a}
	\int_{\Omega} \div \bs a \, d\Omega = \int_\Gamma \bs a \cdot \bs n \, d\Gamma \, , \\
	\label{eq:C.3b}
	\int_{\Omega} \div \bs T \, d\Omega = \int_\Gamma \bs T \cdot \bs n \, d\Gamma  \, , 
\end{align}
\end{subequations}
wobei $\bs n$ die äußere Einheitsnormale auf $\Gamma$ bezeichne.
\end{satz}

\begin{proof}
Standardresultat aus der Analysis 2.
\end{proof}

\begin{kor}[1. Green'sche Formel\index{Integralsatz!Green}\index{1. Green'sche Formel}]\label{kor:C.13}
Es seien $u,v : \Omega \ra \R$ skalarwertige Funktionen. Dann folgt
\begin{align}\label{eq:C.4}
	\int_{\Omega} v \Delta u \, dx + \int_{\Omega} \nabla u \cdot \nabla v \, dx = \int_{\Gamma} v \partial_{\bs n} u \, ds
\end{align}
mit $\partial_{\bs n} u = \nabla u \cdot \bs n$.
\end{kor}

\begin{proof}
Es seien $u,v$ wie vorausgesetzt. Dann ist $\nabla u$ vektorwertig und nach \eqref{eq:C.1} gilt dann
\begin{align*}
	\div (v \cdot \nabla u) & = \nabla v \cdot \nabla u + v \cdot \div(\nabla u) \\
	& =  \nabla v \cdot \nabla u + v \cdot \Delta u \, .
\end{align*}
Weiter gilt wegen \eqref{eq:C.3a}
\[
	\int_{\Omega} \div (v \cdot \nabla u) \, d\Omega = \int_\Gamma v \cdot \underbrace{\nabla u \cdot \bs n}_{=\partial_{\bs n} u} \, d\Gamma \, .
\]
Zusammen mit dem oberen Resultat folgt dann die Behauptung \eqref{eq:C.4}.
\end{proof}




\newchapter{Quellcode}
\label{anhang:D}

\definecolor{mygreen}{RGB}{0,130,0}

\lstset{language=Matlab,
	basicstyle=\scriptsize,%\ttfamily,
	breaklines=true,
	commentstyle=\color{mygreen},
	rulecolor=\color{black},
	numbers=left,
	stepnumber=1,
	numberstyle=\tiny\color{gray},
	stringstyle=\color{purple},
	frame=single,
	xrightmargin=-0.9pt,
	%xleftmargin=1pt,
	literate={-}{-}{1}{<->}{$\leftrightarrow$}{1},%{>=}{$\ge$}{1},
	%tabsize=1,
	keywordstyle=\color{blue},
	captionpos=b,
	breakatwhitespace=true,
	showstringspaces=false,
	deletekeywords={lower,flag,find,abs,max,length,sum,zeros,ones,ceil,size,sqrt,norm,sparse,margin,prod,all,meshgrid,diag,text,num2str,min,legend,axis,full,plot,subplot,title,figure,tic,toc,eps,load,isempty,fprintf},
	morekeywords={switch,case}
	}


\section{Implementierung des Fehlerschätzers für das Hindernisproblem}

Im Folgenden ist der Quellcode angegeben, der für die Implementierung für das in Kapitel \ref{kap:4} beschriebene affine Hindernisproblem geschrieben wurde. Als letztes ist auch die Startdatei für das in Kapitel \ref{kap:6.1} dargestellte numerische Beispiel angegeben.

\lstinputlisting[caption={[Assemblierung von Matrix und Vektor]Assemblierung der Steifigkeitsmatrix $A$ und des Lastvektor $f$},label=lst:D.1]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/assemble.m}

\lstinputlisting[caption={Berechnung der lokalen Anteile von $\rho_{\mcal S}$},label=lst:D.2]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/eval_rho_p.m}

\lstinputlisting[caption={Lösung des lokalen Defektproblems \eqref{eq:4.9}},label=lst:D.3]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/defect_problem_solution.m}

\newpage

\lstinputlisting[caption={[Dreiecksindizes zur Verfeinerung]Berechnung der zu verfeinernden Dreiecksindizes}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/find_triangle_refinement.m}

\lstinputlisting[caption={[Gradientenberechnung]Berechnung des Gradienten von der Galerkin-Approximation auf einem Dreieck},]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/gradu.m}

\lstinputlisting[caption={Bestimmung der inneren Knoten $\mcal N \cap \Omega$}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/inner_points.m}

\lstinputlisting[caption={Bestimmung der inneren Kontaktknoten $\mcal N^0$}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/N0.m}

\lstinputlisting[caption={Bestimmung der inneren Nicht-Kontaktknoten $\mcal N^+$}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/Nplus.m}


\lstinputlisting[caption={Bestimmung der Menge $\mcal N^{++}$}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/Nplusplus.m}

\lstinputlisting[caption={Berechnung der Menge an Knoten aus $\mcal N^{0+}$ und $\mcal N^{0-}$}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/N0plusminus.m}

\lstinputlisting[caption={[Bestimmung der lokalen Steifigkeitsmatrix]Bestimmung der lokalen Steifigkeitsmatrix im linearen und quadratischen Fall}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/local_mat.m}

\lstinputlisting[caption={Berechnung der Indizes anliegender Dreiecke}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/neighbourhood.m}

\lstinputlisting[caption={Bestimmung der Mittelpunkte und Zuordnung zu den Dreiecken}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/midpoints_of_triangle.m}

\lstinputlisting[caption={Berechnung der Normalflüsse $j_E$ für alle $E\in \mcal E_p$}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/normal_flux.m}

\lstinputlisting[caption={Bestimmung der Oszillation $\osc_1(u_{\mcal S},\psi)$}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/osc1.m}

\lstinputlisting[caption={Berechnung der Oszillationsterme $\osc_2(u_{\mcal S},\psi,f)$}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/osc2.m}

\lstinputlisting[caption={Gewichte und Stützstellen für die Quadratur}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/quad_tri.m}

\lstinputlisting[caption={Adaptive Verfeinerung des Gitters und Lösung des Hindernisproblems}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/adaptive_refinement_solution.m}

\lstinputlisting[caption={Startdatei des Problems}]{/Users/cornelius/Documents/MATLAB/DiplomarbeitMatlab/EinfachesHindernisproblem/start.m}


%\newpage
%\newchapter{noch mehr Quellcode}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "Skript"
%%% End: 
